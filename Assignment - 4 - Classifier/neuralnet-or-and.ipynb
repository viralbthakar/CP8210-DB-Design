{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from numpy import heaviside\n",
    "import numpy as np\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AND gate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An AND gate receives two inputs (a, b) and returns an output as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\na|b|out\\n0|0|0\\n0|1|0\\n1|0|0\\n1|1|1\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "a|b|out\n",
    "0|0|0\n",
    "0|1|0\n",
    "1|0|0\n",
    "1|1|1\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagining an activation function of the heavside step function `step(x, c)` where `1 if x >= c and 0 if x < c` and letting c = 0.5, one can begin to see how this activation function on a single neuron (perceptron) will allow for an ANN to compute the AND of two inputs. <br>\n",
    "By setting a function `f(x1, x2) = step(w1*x1+w2*x2+b, 0.5)` and solving for w1, w1, b with respect to the following<br>\n",
    "> `1 = step(w1*1+w2*1+b, 0.5)`<br>\n",
    "> `0 = step(w1*0+w2*1+b, 0.5)`<br>\n",
    "> `0 = step(w1*1+w2*0+b, 0.5)`<br>\n",
    "> `0 = step(w1*0+w2*0+b, 0.5)`<br>\n",
    "Then simplifying<br>\n",
    "> `1 = step(w1+w2+b, 0.5)`<br>\n",
    "> `0 = step(w2+b, 0.5)`<br>\n",
    "> `0 = step(w1+b, 0.5)`<br>\n",
    "> `0 = step(b, 0.5)`<br>\n",
    "It is clear that a solution to the system of equations has `w1=0.25, w2=0.25, b=0`<br>\n",
    "Also, it is clear that only a single neuron is necessary to create an AND gate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAATe0lEQVR4nO3dcZDc5X3f8ffHEkrkmkSuOWIjZEMSrJjYpoYD0zZOcFJXgmYCcT0ZsMcExhlMCq6btBrAE9tNSYIdxVOSgiPLRHGddEJbWyVKBltNJsG4Q0l1AgzIWB4VYnSSXR3GOLVRByS+/WMXZjn2bvfw7h338H7N3Gh/z/Ps7/k+upvP/e63v99uqgpJ0vL3kqUuQJI0Gga6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBrkWT5G+T/JPu40uSVJJNs8ZMJzmn+/jfJnkyyXeSPJbkjiT/sKfvj/vMUUl+NMme7vO+k+Rokv/Xs/2BJKuSfKw733eSPJTk389R94lJvpXkJ3ra1nXb3tzd/oVufY8nuW2B/y8fS7JzVtv1Sf68+/jsJH+R5NEkM0n+a5JXLWQOvTgY6FpKjwJXJfmBecb856p6GTAB/A9ge5IM2nFV/XhVvaz73C8CVz69XVW/BVwDTAJnAccCbwXunmNf08BVwE1Jvr/b/AngD6vqb3rWcj3wkUG19fFB4EeSXArQ/aX1i8Dl3f6XA1uBk4DXAP8X+MPnMY8at3KpC9CL2gPAt4BfAX59voFV9WSS/whsAl4xgrnPBP5bVR3sbv9t92sunwQuAj6c5CvAeuAdPfX9JUCSX1poIVX1ePd5n03y18A24OruLxKq6nO945PcAHxhofOofQa6ltoHgduS/IeqenSuQUm+D7gEmK6qR4Y4SB/kTuBXkzxB5wj+/prnfTCqqrqhexfwFPDPq+rx77WInv3fluQzwBRwP50j8rn8JLBnVHOrHZ5y0ZKqqnuA/07nlEY/v5DkMWA/cAZwwYimvg74KPAuOiF6IMkvDnjO14CDwN8Bt4+ojl5fpPPXx3+a65dLkjcCH6Lzl4r0LAa6Xgg+BPxyklf26fsvVbWmqo6vqp+uqt3d9iPAMb0Dkzy9/eSgCavqaFXdWFX/GFgD/CawLcnr5nna1cA3gUPAvxk0x0IkeQXwO3TOw/+7JGv6jPlR4HPA+6vqi6OcX20w0LXkquorwHbgAwt42sN0XiTsdTJwFDiwwPkPV9WNdM7nn9pvTJJT6RwV/xLwHuADSU5ZyDwDXA98vqp+hc7R/+/Mmv81wF8C11bVH41wXjXEQNcLxa8Dl9I5Wh7G54H1Sd6d5Jgkfx/4LeAzVXVk0JOT/Ksk5yRZnWRl93TLsfS50iXJS4A/AH67qr5SVfcCvwdsffqKmyQrulfArARekuT7e/5iePqSzUvmqOU84G3Ar3ab3gdckOSt3f61wF8BN1bVlmH+c/TiZKDrBaGqHgL+CPh7Q44/BJwHvJfOKZD7gW8DvzzklIeBjwHfAB4BrqDzQueDfca+H3gp8Ns9bdcCr6RzxA7w7u4+fx94S/fxJwGSrKJzbvzO2TtOciywBfiXT78o3F3bvwY+mWR1d44fpnOFzdPX0n9nyHXqRSR+wIU0Xt0bkq6oqouWuha1zUCXpEZ4ykWSGmGgS1IjDHRJasSS3fp/3HHH1UknnbRU00vSsrR79+5HqmqiX9+SBfpJJ53E1NTUUk0vSctSkq/N1ecpF0lqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjBt5YlGQb8LPAoap6fZ/+AL9L572pHwcuqaq7Rl3obLfcfYDNO/dy8LHDnLBmNZs2rOeCN60d97SStCC7dnyCdXdt5via4VAm2H/6Js78ufeOZa5hjtA/BWycp/9c4JTu12V03uB/rG65+wDXbL+PA48dpoADjx3mmu33ccvdC/rkMUkaq107PsHrd/8ar2SGlwReyQyv3/1r7NrxibHMNzDQq+p24NF5hpwPfLo67gTWJHnVqArsZ/POvRx+8uiz2g4/eZTNO/eOc1pJWpB1d21mdZ54VtvqPMG6uzaPZb5RnENfC+zv2Z7utj1HksuSTCWZmpmZed4THnzs8ILaJWkpHF/9c+74emQs840i0NOnre/HIFXV1qqarKrJiYm+bxY2lBPWrF5QuyQthUPpn3OHctxY5htFoE8D63q2TwQOjmC/c9q0YT2rj1nxrLbVx6xg04b145xWkhZk/+mbOFyrntV2uFax//RNY5lvFIG+A7g4HWcD366qr49gv3O64E1rue7tb2DtmtUEWLtmNde9/Q1e5SLpBeXMn3sv95/xG3yDCZ6q8A0muP+M3xjbVS4DPyQ6yZ8A5wDHAf8H+DBwDEBVbeletngDnSthHgcuraqBb3Q+OTlZvh+6JC1Mkt1VNdmvb+B16FV10YD+Aq54nrVJkkbEO0UlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhoxVKAn2Zhkb5J9Sa7u0/+DSf4syZeS7Ely6ehLlSTNZ2CgJ1kB3AicC5wKXJTk1FnDrgC+XFWnAecAH0uyasS1SpLmMcwR+lnAvqp6sKqeAG4Gzp81poBjkwR4GfAocGSklUqS5jVMoK8F9vdsT3fbet0AvA44CNwHvL+qnhpJhZKkoQwT6OnTVrO2NwD3ACcA/wC4IckPPGdHyWVJppJMzczMLLhYSdLchgn0aWBdz/aJdI7Ee10KbK+OfcBDwI/N3lFVba2qyaqanJiYeL41S5L6GCbQdwGnJDm5+0LnhcCOWWMeBn4GIMkPAeuBB0dZqCRpfisHDaiqI0muBHYCK4BtVbUnyeXd/i3AtcCnktxH5xTNVVX1yBjrliTNMjDQAarqVuDWWW1beh4fBP7paEuTJC2Ed4pKUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRgwV6Ek2JtmbZF+Sq+cYc06Se5LsSfKF0ZYpSRpk5aABSVYANwJvA6aBXUl2VNWXe8asAT4ObKyqh5McP66CJUn9DXOEfhawr6oerKongJuB82eNeSewvaoeBqiqQ6MtU5I0yDCBvhbY37M93W3r9Vrg5UluS7I7ycX9dpTksiRTSaZmZmaeX8WSpL6GCfT0aatZ2yuBM4B/BmwAPpjktc95UtXWqpqsqsmJiYkFFytJmtvAc+h0jsjX9WyfCBzsM+aRqvou8N0ktwOnAV8dSZWSpIGGOULfBZyS5OQkq4ALgR2zxvwp8JYkK5O8FHgz8MBoS5UkzWfgEXpVHUlyJbATWAFsq6o9SS7v9m+pqgeSfB64F3gKuKmq7h9n4ZKkZ0vV7NPhi2NycrKmpqaWZG5JWq6S7K6qyX593ikqSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktSIoQI9ycYke5PsS3L1POPOTHI0yTtGV6IkaRgDAz3JCuBG4FzgVOCiJKfOMe6jwM5RFylJGmyYI/SzgH1V9WBVPQHcDJzfZ9z7gM8Ch0ZYnyRpSMME+lpgf8/2dLftGUnWAj8PbJlvR0kuSzKVZGpmZmahtUqS5jFMoKdPW83avh64qqqOzrejqtpaVZNVNTkxMTFsjZKkIawcYsw0sK5n+0Tg4Kwxk8DNSQCOA85LcqSqbhlJlZKkgYYJ9F3AKUlOBg4AFwLv7B1QVSc//TjJp4A/N8wlaXENDPSqOpLkSjpXr6wAtlXVniSXd/vnPW8uSVocwxyhU1W3ArfOausb5FV1yfdeliRpobxTVJIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDViqEBPsjHJ3iT7klzdp/9dSe7tft2R5LTRlypJms/AQE+yArgROBc4Fbgoyamzhj0E/FRVvRG4Ftg66kIlSfMb5gj9LGBfVT1YVU8ANwPn9w6oqjuq6lvdzTuBE0dbpiRpkGECfS2wv2d7uts2l/cAn+vXkeSyJFNJpmZmZoavUpI00DCBnj5t1Xdg8lY6gX5Vv/6q2lpVk1U1OTExMXyVkqSBVg4xZhpY17N9InBw9qAkbwRuAs6tqm+OpjxJ0rCGOULfBZyS5OQkq4ALgR29A5K8GtgOvLuqvjr6MiVJgww8Qq+qI0muBHYCK4BtVbUnyeXd/i3Ah4BXAB9PAnCkqibHV7YkabZU9T0dPnaTk5M1NTW1JHNL0nKVZPdcB8zeKSpJjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1IiVwwxKshH4XWAFcFNVfWRWf7r95wGPA5dU1V0jrvVZbrn7AJt37uXgY4c5Yc1qNm1YzwVvWjvOKSVpwRYzqwYGepIVwI3A24BpYFeSHVX15Z5h5wKndL/eDPx+99+xuOXuA1yz/T4OP3kUgAOPHeaa7fcBGOqSXjAWO6uGOeVyFrCvqh6sqieAm4HzZ405H/h0ddwJrEnyqhHX+ozNO/c+8x/0tMNPHmXzzr3jmlKSFmyxs2qYQF8L7O/Znu62LXQMSS5LMpVkamZmZqG1PuPgY4cX1C5JS2Gxs2qYQE+ftnoeY6iqrVU1WVWTExMTw9TX1wlrVi+oXZKWwmJn1TCBPg2s69k+ETj4PMaMzKYN61l9zIpnta0+ZgWbNqwf15SStGCLnVXDBPou4JQkJydZBVwI7Jg1ZgdwcTrOBr5dVV8fca3PuOBNa7nu7W9g7ZrVBFi7ZjXXvf0NviAq6QVlsbMqVc85M/LcQcl5wPV0LlvcVlW/meRygKra0r1s8QZgI53LFi+tqqn59jk5OVlTU/MOkSTNkmR3VU326xvqOvSquhW4dVbblp7HBVzxvRQpSfreeKeoJDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNGOrGorFMnMwAXxvBro4DHhnBfpYL19uuF9NawfU+X6+pqr5vhrVkgT4qSabmumuqRa63XS+mtYLrHQdPuUhSIwx0SWpEC4G+dakLWGSut10vprWC6x25ZX8OXZLU0cIRuiQJA12SmrFsAj3JxiR7k+xLcnWf/iT5vW7/vUlOX4o6R2GItb6ru8Z7k9yR5LSlqHNUBq23Z9yZSY4mecdi1jdqw6w3yTlJ7kmyJ8kXFrvGURri5/kHk/xZki9113vpUtQ5Ckm2JTmU5P45+sebU1X1gv+i80lJ/xv4YWAV8CXg1FljzgM+R+cDq88G/map6x7jWv8R8PLu43OX61qHXW/PuL+i80Er71jqusf8/V0DfBl4dXf7+KWue8zr/QDw0e7jCeBRYNVS1/481/uTwOnA/XP0jzWnlssR+lnAvqp6sKqeAG4Gzp815nzg09VxJ7AmyasWu9ARGLjWqrqjqr7V3byTzodyL1fDfG8B3gd8Fji0mMWNwTDrfSewvaoeBqiq5bzmYdZbwLHdj7J8GZ1AP7K4ZY5GVd1Op/65jDWnlkugrwX292xPd9sWOmY5WOg63kPnN/5yNXC9SdYCPw9sYfkb5vv7WuDlSW5LsjvJxYtW3egNs94bgNcBB4H7gPdX1VOLU96iG2tODfWZoi8A6dM2+3rLYcYsB0OvI8lb6QT6T4y1ovEaZr3XA1dV1dHOQdyyNsx6VwJnAD8DrAb+Z5I7q+qr4y5uDIZZ7wbgHuCngR8B/iLJF6vq78Zd3BIYa04tl0CfBtb1bJ9I57f5QscsB0OtI8kbgZuAc6vqm4tU2zgMs95J4OZumB8HnJfkSFXdsjgljtSwP8uPVNV3ge8muR04DViOgT7Mei8FPlKdk8z7kjwE/BjwvxanxEU11pxaLqdcdgGnJDk5ySrgQmDHrDE7gIu7ryKfDXy7qr6+2IWOwMC1Jnk1sB149zI9aus1cL1VdXJVnVRVJwGfAf7FMg1zGO5n+U+BtyRZmeSlwJuBBxa5zlEZZr0P0/lrhCQ/BKwHHlzUKhfPWHNqWRyhV9WRJFcCO+m8ar6tqvYkubzbv4XO1Q/nAfuAx+n81l92hlzrh4BXAB/vHrUeqWX6rnVDrrcZw6y3qh5I8nngXuAp4Kaq6nsZ3AvdkN/fa4FPJbmPzimJq6pqWb6tbpI/Ac4BjksyDXwYOAYWJ6e89V+SGrFcTrlIkgYw0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1Ij/j+tCKW9JJj70QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1 = [1,1,0,0] \n",
    "x2 = [1,0,1,0]\n",
    "plt.scatter(x1, x2)\n",
    "plt.scatter([x1[0]],[x2[0]])\n",
    "plt.title(\"INPUTS X1, X2\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AND function with single neuron, and proper weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 AND 1 |1\n",
      "1 AND 0 |0\n",
      "0 AND 1 |0\n",
      "0 AND 0 |0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def and_gate(x):\n",
    "    y = (0.25*x[0])+(0.25*x[1])\n",
    "    return 0 if y < 0.5 else 1\n",
    "X = [[1,1], [1,0], [0,1], [0,0]] \n",
    "y = [1, 0, 0, 0]\n",
    "for x in range(4):\n",
    "    print(X[x][0], \"AND\", X[x][1], \"|\",end=\"\")\n",
    "    print(and_gate(X[x]))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But can a perceptron learn the AND function?\n",
    "Well it should be able to. This is because the AND function is linearly seperable.<br>\n",
    "\n",
    "A perceptron is a linear function that finds some hyperplane to seperate data into two classes. <br> \n",
    "\n",
    "In this case *hyperplane* is referring to the linear boundary which splits data into two categories represented by the line orthagonal to $t=x1*w1+x2*w2$ where t is the threshold for the step function, and t=0.5 <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 18091.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTING EQUATION: y=0.49999999999999956*x1+0.49999999999999956*x2\n",
      "INPUT PREDICTED REAL\n",
      "[1, 0] \t 0 \t 0\n",
      "[1, 1] \t 1 \t 1\n",
      "[0, 1] \t 0 \t 0\n",
      "[0, 0] \t 0 \t 0\n",
      "ACCURACY: 100.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance\n",
    "def step(input):\n",
    "    return 0 if input < 0.5 else 1\n",
    "def neural_func(x, weights):\n",
    "    return np.dot(x, weights)\n",
    "def train(X, y, learning_rate, epochs = 30):\n",
    "    weights = [1,1]\n",
    "    for _ in tqdm(range(epochs)):\n",
    "        for x in range(4):\n",
    "            pred = step(neural_func(X[x], weights))\n",
    "            #Optimal hyperplane exists where 0.5=w1x1+w2x2. So subtracting the weight gradient from weights when w1x1+w2x2 >= 0.5\n",
    "            # will force the hyperplane to converge to 0.5\n",
    "            if neural_func(X[x], weights) >= 0.5:\n",
    "                #Weight gradients are d/dw1(w1x1+w2x2+b)=x1 and d/dw2(w1x1+w2x2+b)=x2\n",
    "                weights[0] -= learning_rate*X[x][0]\n",
    "                weights[1] -= learning_rate*X[x][1] \n",
    "    return weights\n",
    "def test(test_x, test_y, optimal_weights):\n",
    "    accuracies = []\n",
    "\n",
    "    print(f\"RESULTING EQUATION: y={optimal_weights[0]}*x1+{optimal_weights[1]}*x2\")\n",
    "    print(\"INPUT\", \"PREDICTED\", \"REAL\")\n",
    "    for x in range(len(test_x)):\n",
    "        # print(neural_func(, optimal_weights))\n",
    "        print(test_x[x],\"\\t\",step(neural_func(test_x[x], optimal_weights)), \"\\t\",test_y[x])\n",
    "        if step(neural_func(test_x[x], optimal_weights))==test_y[x]:\n",
    "            accuracies.append(1)\n",
    "        else:\n",
    "            accuracies.append(0)\n",
    "    print(\"ACCURACY:\", 100*sum(accuracies)/len(accuracies), \"%\")\n",
    "    return 100*sum(accuracies)/len(accuracies)\n",
    "test([[1,0], [1,1], [0,1], [0,0]], [0,1,0,0], train(X, y, 0.01, 25))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR GATE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use our method from the AND gate section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 4957.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTING EQUATION: y=0.994*x1+0.994*x2\n",
      "INPUT PREDICTED REAL\n",
      "[1, 1] \t 1 \t 1\n",
      "[0, 1] \t 1 \t 1\n",
      "[1, 0] \t 1 \t 1\n",
      "[0, 0] \t 0 \t 0\n",
      "ACCURACY: 100.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[1,1],[0,1],[1,0],[0,0]]\n",
    "y = [1,1,1,0]\n",
    "test(X, y, train(X, y, 0.001, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
